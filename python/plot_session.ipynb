{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psychofit as psy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join, splitext\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['cwStimOn', 'cwTrials', 'cwGoCue', 'cwResponse', 'Wheel', 'cwFeedback'])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def plot_session(subject, date, subsession, exp_ref=None, root_dir=None):\n",
    "    if rootDir is None:\n",
    "        rootDir = r'\\\\zubjects.cortexlab.net\\Subjects'\n",
    "    fullpath = join(rootDir, subject, date, str(subsession))\n",
    "    load_alfs(fullpath)\n",
    "    #feedback = np.load(join(fullpath, alfs[0]))\n",
    "    return\n",
    "ans = plot_session('ALK081', '2018-08-28', 1)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ref(ref):\n",
    "    pattern = r'(?P<date>^[0-9\\-]+)_(?P<seq>\\d+)_(?P<subject>\\w+)'\n",
    "    try:\n",
    "        out = re.match(pattern,ref).groupdict()\n",
    "    except:\n",
    "        raise ValueError('%s could not be parsed', ref)\n",
    "    return out['subject'], datetime.strptime(out['date'], '%Y-%m-%d'), int(out['seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "subject, date, seq = parse_ref('2018-08-27_1_fhuads')\n",
    "print(type(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expPath(ref, rootDir):\n",
    "    subject, date, seq = parse_ref(ref)\n",
    "    path = join(rootDir, subject, date.strftime('%Y-%m-%d'), str(seq))\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_alf(fileName):\n",
    "    ''' Return logical array the length of list, of whether a given file name is ALF'''\n",
    "    pattern = r'(?P<obj>.+)\\.(?P<typ>.+)\\.(?P<ext>.+)'\n",
    "    out = re.match(pattern,file_name)\n",
    "    return out is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alf_parts(fileName):\n",
    "    ''' Return the object, type and extention for a given ALF file name'''\n",
    "    '''TODO: Deal with namespaces'''\n",
    "    obj, typ, ext = file_name.split('.')\n",
    "    return obj, typ, ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_alfs(fullpath):\n",
    "    '''Takes a path and loads alfs into dataframes based on object'''\n",
    "    alfs = [f for f in listdir(fullpath) if (isfile(join(fullpath, f))) & (is_alf(f))]\n",
    "    parts = [alf_parts(alf) for alf in alfs]\n",
    "    behaviour = dict.fromkeys(set([x[0] for x in parts]))\n",
    "    for alf in parts:\n",
    "        behaviour[alf[0]]\n",
    "        \n",
    "    print(behaviour.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwFeedback.type.npy\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(f[4])\n",
    "print(is_alf(f[4])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data must be a list or numpy array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-176-71df1acec645>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_behaviour\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2018-09-07_1_LEW009'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mplot_performance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-175-45f08dd501a2>\u001b[0m in \u001b[0;36mplot_performance\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mpp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'contrast'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'included'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'feedbackType'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcontrastSet\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontrastSet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mpars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpsy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmle_fit_psycho\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrastSet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpp\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'erf_psycho'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mpars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\psychofit.py\u001b[0m in \u001b[0;36mmle_fit_psycho\u001b[1;34m(data, P_model, parstart, parmin, parmax, nfits)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data must be a list or numpy array'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: data must be a list or numpy array"
     ]
    }
   ],
   "source": [
    "def load_behaviour(ref, rootDir=None):\n",
    "    '''TODO: Deal with namespaces'''\n",
    "    if rootDir is None:\n",
    "        rootDir = r'\\\\zubjects.cortexlab.net\\Subjects'\n",
    "    path = expPath(ref, rootDir)\n",
    "    alfs = [f for f in listdir(path) if (isfile(join(path, f))) & (is_alf(f))]\n",
    "    parts = [alf_parts(alf) for alf in alfs]\n",
    "    # List of 'trials' attributes\n",
    "    attr = [parts[i][1] for i in range(len(parts)) if parts[i][0].startswith('_ibl_trials')]\n",
    "    attr.extend(['trialStart', 'trialEnd'])\n",
    "    # Pull paths of trials ALFs\n",
    "    trials = [join(path,f) for f in alfs if f.startswith('_ibl_trials')]\n",
    "    # Load arrays into dictionary\n",
    "    trialsDict = dict.fromkeys(attr)\n",
    "    for p,name in zip(trials, attr):\n",
    "        trialsDict[name] = np.load(p).squeeze()\n",
    "    # Check all arrays the same length\n",
    "    lengths = [len(val) for val in [trialsDict.values()]]\n",
    "    assert len(set(lengths))==1,'Not all arrays in trials the same length'\n",
    "    # Deal with intervals\n",
    "    trialsDict['trialStart'] = trialsDict['intervals'][:,0]\n",
    "    trialsDict['trialEnd'] = trialsDict['intervals'][:,1]\n",
    "    trialsDict.pop('intervals', None)\n",
    "    # Create data from from trials dict\n",
    "    df = pd.DataFrame(trialsDict)\n",
    "    return df\n",
    "df = load_behaviour('2018-09-07_1_LEW009')\n",
    "plot_performance(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(df):\n",
    "    df['contrast'] = df['contrastRight']-df['contrastLeft']\n",
    "    contrastSet = df['contrast'].unique()\n",
    "    choiceSet = np.array(set(df['choice']))\n",
    "    nn = np.array([sum((df['contrast']==c) & (df['included']==True)) for c in contrastSet])\n",
    "    pp = np.array([sum((df['contrast']==c) & (df['included']==True) & (df['feedbackType']==1.)) for c in contrastSet])\n",
    "    if contrastSet.size > 2:\n",
    "        pars, L = psy.mle_fit_psycho((contrastSet,nn,pp/nn), P_model='erf_psycho')\n",
    "    else:\n",
    "        pars = None\n",
    "    \n",
    "    return pars"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
